{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:32.832555Z",
     "start_time": "2018-07-08T19:19:32.556660Z"
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:39.662477Z",
     "start_time": "2018-07-08T19:19:32.834229Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gc\n",
    "import subprocess\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('./stylelib/custom.mplstyle')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import preprocessing\n",
    "import plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1 Data inspection and loading\n",
    "### 1.1 Downsample training data\n",
    "Only 0.5% of the all training records is used for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:39.694809Z",
     "start_time": "2018-07-08T19:19:39.664287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1 µs, total: 12 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_data = './data'\n",
    "from_scratch = False\n",
    "\n",
    "csv_train_raw = os.path.join(dir_data, 'train.csv')\n",
    "csv_train = os.path.join(dir_data, 'train_sample.csv')\n",
    "if from_scratch:\n",
    "    nlines_raw, nlines_reduced = preprocessing.csv_randomized_downsamp(\n",
    "        csv_in=csv_train_raw, csv_out=csv_train, fraction=0.005\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data into dataframe\n",
    "#### (1) Field inspections\n",
    "For efficiency concerns, we use shell commands instead of pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:39.877242Z",
     "start_time": "2018-07-08T19:19:39.697351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip,app,device,os,channel,click_time,attributed_time,is_attributed\r\n",
      "106284,15,1,41,277,2017-11-06 22:57:46,,0\r\n"
     ]
    }
   ],
   "source": [
    "# Quick check of training data fields by calling system shell command\n",
    "!head -2 ./data/train_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.064655Z",
     "start_time": "2018-07-08T19:19:39.879656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click_id,ip,app,device,os,channel,click_time\r\n",
      "0,5744,9,1,3,107,2017-11-10 04:00:00\r\n"
     ]
    }
   ],
   "source": [
    "# Quick check of test data fields by calling system shell command\n",
    "!head -2 ./data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[CAUTION]** We should be very careful about the use of datetime feature `click_time`. The simple check above indicates the date value of the training and testing data don't overlap. For this reason, we should NOT use raw date or day-of-the-week as a feature when training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Notes] Field selections** <br>\n",
    "Note that from above that training and testing data don't share the same fields. <br>\n",
    "To prepare data for subsequent processing, we only preserve fields that are common in both training and testing data. One exception is the `is_attributed` field in training data; It is the prediction target and thus needs to be preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.114844Z",
     "start_time": "2018-07-08T19:19:40.066903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fields shared by both training and testing data:\n",
      " ['channel', 'device', 'app', 'os', 'click_time', 'ip']\n"
     ]
    }
   ],
   "source": [
    "# Extract field names from training and testing data\n",
    "fields_train = preprocessing.csv_list_fields(csv_in=csv_train)\n",
    "csv_test = os.path.join(dir_data, 'test.csv')\n",
    "fields_test = preprocessing.csv_list_fields(csv_in=csv_test)\n",
    "\n",
    "# Extract fields shared by both training and testing data\n",
    "fields_use = list(set(fields_train) & (set(fields_test)))\n",
    "print('Data fields shared by both training and testing data:\\n', fields_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Load into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.352174Z",
     "start_time": "2018-07-08T19:19:40.117640Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-17482467b9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load randomly sampled data subset into pandas dataframe,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# and sort by click time (and reset index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m df = pd.read_csv(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcsv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields_use\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'is_attributed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load randomly sampled data subset into pandas dataframe,\n",
    "# and sort by click time (and reset index)\n",
    "df = pd.read_csv(\n",
    "    csv_train, usecols=fields_use + ['is_attributed'],\n",
    "    parse_dates=['click_time']\n",
    ").sort_values(by='click_time').reset_index(drop=True)\n",
    "\n",
    "# Convert click time from UTC to local time\n",
    "df['click_time'] = (\n",
    "    pd.DatetimeIndex(df['click_time']).tz_localize('utc')\n",
    "    .tz_convert('Asia/Shanghai')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.352967Z",
     "start_time": "2018-07-08T19:19:32.570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect first few lines\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploratory data analysis\n",
    "### 2.1 Do we have imbalanced classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.353893Z",
     "start_time": "2018-07-08T19:19:32.572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect data size\n",
    "nclick_total =len(df)\n",
    "percentage_pos = (df['is_attributed'].sum()) / nclick_total * 100\n",
    "print('Percentage of positive target = {:.3f}%'.format(percentage_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[CAUTION] Class imbalance**<br>\n",
    "Given that only ~0.25% of the records has positive target values (`df['is_attributed'] == 1`), we have **an extreme case of class imbalance** at hand.\n",
    "\n",
    "### 2.2 Convert datetime variable to usable form\n",
    "To convert datetime to a more usable form, we extract hour-of-the-day information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.354628Z",
     "start_time": "2018-07-08T19:19:32.573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract hour of the day\n",
    "df['click_hour'] = df['click_time'].dt.hour\n",
    "\n",
    "# Drop raw `click_time`\n",
    "df.drop(columns=['click_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.355348Z",
     "start_time": "2018-07-08T19:19:32.576Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train-test split, and set aside testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.356117Z",
     "start_time": "2018-07-08T19:19:32.578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the original dataframe into in-sample training and testing sets\n",
    "# Because stratified sampling is the default option of sklearn, it is not\n",
    "# explicitly set\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Double check class ratios after train-test split\n",
    "print(\n",
    "    'Training data (pos%):',\n",
    "    100 * df_train['is_attributed'].sum() / len(df_train)\n",
    ")\n",
    "print(\n",
    "    'Testing data (pos%):',\n",
    "    100 * df_test['is_attributed'].sum() / len(df_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Inspect variable distributions of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.358013Z",
     "start_time": "2018-07-08T19:19:32.580Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count the amount of unique values\n",
    "df_counts = pd.DataFrame()\n",
    "df_counts['n_unique'] = df_train.nunique()\n",
    "df_counts['n_unique (%)'] = 100 * df_counts['n_unique'] / len(df_train)\n",
    "df_counts.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TAKE AWAY]**<br>\n",
    "* Without exception, the total number of unique values for each of these variables is markedly smaller than the total number of clicks. This indicates that many-to-one mapping is typical between clicks and these variables. This makes sense because a single user can generate multiple clicks.\n",
    "* The amount of distinct values in categorical features is very high. We will need to make major efforts in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.358683Z",
     "start_time": "2018-07-08T19:19:32.581Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_list = [col for col in df_train.columns if col != 'is_attributed']\n",
    "df_train_imputed, df_test_imputed = preprocessing.df_rarelabel_imputer(\n",
    "    df_train, df_test, cols=feature_list,\n",
    "    thresh_percentage=0.2, replace_with=1e10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.359776Z",
     "start_time": "2018-07-08T19:19:32.583Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Apply target-guided encoding to categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.360654Z",
     "start_time": "2018-07-08T19:19:32.584Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = preprocessing.df_label2num_encoding(\n",
    "    df_train, df_test, cols=feature_list\n",
    ")\n",
    "df_train_imputed, df_test_imputed = preprocessing.df_label2num_encoding(\n",
    "    df_train_imputed, df_test_imputed, cols=feature_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Check dataframes after encoding\n",
    "\n",
    "Note that mapping used for encoding is generated with training data and then propagated to testing data. \n",
    "Because there are non-overlap variables between training and testing data, and encoded testing data are going to have missing values. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.361462Z",
     "start_time": "2018-07-08T19:19:32.586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check presence of missing value after encoding\n",
    "df_nulls = pd.DataFrame()\n",
    "df_nulls['nan_train(%)'] = 100 * (df_train.isnull().sum() / len(df_train))\n",
    "df_nulls['nan_test(%)'] = 100 * (df_test.isnull().sum() / len(df_test))\n",
    "df_nulls.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, for `*_woe` variables, the testing data have missing values that requires clean up. We will test a number of approaches later, and use simply dropping the value as a baseline for comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Check Pearson's correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.362276Z",
     "start_time": "2018-07-08T19:19:32.589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exclude target variable from correlation calculation\n",
    "plotter.plot_corrmat(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.363434Z",
     "start_time": "2018-07-08T19:19:32.590Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_2_Xy(impute=True):\n",
    "    target_col = 'is_attributed'\n",
    "    cols = [x for x in df_train.columns if x != target_col]\n",
    "    #cols = [x for x in df_train.columns if x != target_col and 'count' not in x]\n",
    "    #cols = [x for x in df_train.columns if x != target_col and 'risk' not in x]\n",
    "    if impute:\n",
    "        df_train_imputed.fillna(0.0, inplace=True)\n",
    "        df_test_imputed.fillna(0.0, inplace=True)\n",
    "        X_train, y_train = (\n",
    "            df_train_imputed[cols], df_train_imputed[target_col]\n",
    "        )\n",
    "        X_test, y_test = (\n",
    "            df_test_imputed[cols], df_test_imputed[target_col]\n",
    "        )\n",
    "    else:\n",
    "        df_train.fillna(0.0, inplace=True)\n",
    "        df_test.fillna(0.0, inplace=True)\n",
    "        X_train, y_train = (df_train[cols], df_train[target_col])\n",
    "        X_test, y_test = (df_test[cols], df_test[target_col])\n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.364364Z",
     "start_time": "2018-07-08T19:19:32.591Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = df_2_Xy(impute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.366317Z",
     "start_time": "2018-07-08T19:19:32.592Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import (cross_val_score, RandomizedSearchCV)\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.367361Z",
     "start_time": "2018-07-08T19:19:32.594Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.368381Z",
     "start_time": "2018-07-08T19:19:32.595Z"
    }
   },
   "outputs": [],
   "source": [
    "lgc = LogisticRegression(class_weight='balanced', C=100)\n",
    "lgc.fit(X_train, y_train)\n",
    "y_pred = lgc.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(thresholds)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "plt.show();\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recalls, precisions)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.369481Z",
     "start_time": "2018-07-08T19:19:32.597Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.370739Z",
     "start_time": "2018-07-08T19:19:32.598Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    class_weight='balanced', max_depth=6, criterion='entropy'\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(thresholds)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "plt.show();\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recalls, precisions)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.371700Z",
     "start_time": "2018-07-08T19:19:32.601Z"
    }
   },
   "outputs": [],
   "source": [
    "index = np.argsort(model.feature_importances_).astype(int)[::-1]\n",
    "print(index)\n",
    "features = np.array([x for x in df_train.columns if x != 'is_attributed'])\n",
    "features[index]\n",
    "model.feature_importances_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.372757Z",
     "start_time": "2018-07-08T19:19:32.602Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    class_weight='balanced', n_estimators=40, max_depth=3,\n",
    "    criterion='gini'\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.373581Z",
     "start_time": "2018-07-08T19:19:32.604Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight.compute_class_weight(\n",
    "    'balanced', np.unique(y_train), y_train\n",
    ")\n",
    "print(np.unique(y_train))\n",
    "\n",
    "200.48420074 / 0.5012501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.374322Z",
     "start_time": "2018-07-08T19:19:32.605Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [x for x in df_train.columns if x != 'is_attributed']\n",
    "[print(i, x) for i, x in enumerate(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.375265Z",
     "start_time": "2018-07-08T19:19:32.607Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "param = {'max_depth':2, 'num_trees':100, 'objective':'binary', 'is_unbalanced': True}\n",
    "\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "print(y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.376162Z",
     "start_time": "2018-07-08T19:19:32.608Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(\n",
    "    class_weight='balanced', n_estimators=40, max_depth=3,\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:19:40.377072Z",
     "start_time": "2018-07-08T19:19:32.610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLNDcapstone_pipeline.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
