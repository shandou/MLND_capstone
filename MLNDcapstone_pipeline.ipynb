{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:16.812214Z",
     "start_time": "2018-07-19T16:31:16.549682Z"
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:17.329898Z",
     "start_time": "2018-07-19T16:31:16.814659Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gc\n",
    "import subprocess\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('./stylelib/custom.mplstyle')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import preprocessing\n",
    "import plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1 Data inspection and loading\n",
    "### 1.1 Downsample training data\n",
    "__Data size considerations__: The raw training data from kaggle has close to 200 million lines and takes 7 GB of memory. To keep EDA and evaluation steps of machine learning algorithms lightweight, a randomly sampled subset (0.5%) is used for EDA and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:17.364744Z",
     "start_time": "2018-07-19T16:31:17.331690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 1e+03 ns, total: 13 µs\n",
      "Wall time: 15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_data = './data'\n",
    "from_scratch = False\n",
    "\n",
    "# When from_scratch = True, generate randomly sampled subset\n",
    "csv_train_raw = os.path.join(dir_data, 'train.csv')\n",
    "csv_train = os.path.join(dir_data, 'train_sample.csv')\n",
    "if from_scratch:\n",
    "    nlines_raw, nlines_reduced = preprocessing.csv_randomized_downsamp(\n",
    "        csv_in=csv_train_raw, csv_out=csv_train, fraction=0.005\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data into dataframe\n",
    "#### (1) Field inspections\n",
    "For efficiency concerns, we use shell commands instead of pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:17.515785Z",
     "start_time": "2018-07-19T16:31:17.367479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip,app,device,os,channel,click_time,attributed_time,is_attributed\r\n",
      "106284,15,1,41,277,2017-11-06 22:57:46,,0\r\n"
     ]
    }
   ],
   "source": [
    "# Quick check of training data fields by calling system shell command\n",
    "!head -2 ./data/train_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:17.665947Z",
     "start_time": "2018-07-19T16:31:17.518297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click_id,ip,app,device,os,channel,click_time\r\n",
      "0,5744,9,1,3,107,2017-11-10 04:00:00\r\n"
     ]
    }
   ],
   "source": [
    "# Quick check of test data fields by calling system shell command\n",
    "!head -2 ./data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Notes] Field selections** <br>\n",
    "Field inspection tells us that training and testing data don't share the same fields. \n",
    "To prepare data for subsequent processing, we only preserve fields that are shared by both training and testing data. One exception is the `is_attributed` field in training data; It is the prediction target and thus needs to be preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:17.725690Z",
     "start_time": "2018-07-19T16:31:17.667856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fields shared by both training and testing data:\n",
      " ['channel', 'device', 'os', 'app', 'click_time', 'ip']\n"
     ]
    }
   ],
   "source": [
    "# Extract field names from training and testing data\n",
    "fields_train = preprocessing.csv_list_fields(csv_in=csv_train)\n",
    "csv_test = os.path.join(dir_data, 'test.csv')\n",
    "fields_test = preprocessing.csv_list_fields(csv_in=csv_test)\n",
    "\n",
    "# Extract fields shared by both training and testing data\n",
    "fields_keep = list(set(fields_train) & (set(fields_test)))\n",
    "print('Data fields shared by both training and testing data:\\n', fields_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Load into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.356422Z",
     "start_time": "2018-07-19T16:31:17.729016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load randomly sampled data subset into pandas dataframe,\n",
    "# and sort by click time (and reset index)\n",
    "df = pd.read_csv(\n",
    "    csv_train, usecols=fields_keep + ['is_attributed'],\n",
    "    parse_dates=['click_time']\n",
    ").sort_values(by='click_time').reset_index(drop=True)\n",
    "\n",
    "# Convert click time from UTC to local time\n",
    "df['click_time'] = (\n",
    "    pd.DatetimeIndex(df['click_time']).tz_localize('utc')\n",
    "    .tz_convert('Asia/Shanghai')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.399805Z",
     "start_time": "2018-07-19T16:31:19.358258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86946</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 23:46:14+08:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119349</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 23:57:47+08:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73516</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-07 00:00:00+08:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel                click_time  is_attributed\n",
       "0   86946    3       1  19      379 2017-11-06 23:46:14+08:00              0\n",
       "1  119349    3       1  17      379 2017-11-06 23:57:47+08:00              0\n",
       "2   73516   18       1  22      107 2017-11-07 00:00:00+08:00              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect first few lines\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploratory data analysis\n",
    "### 2.1 Examine class proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.434302Z",
     "start_time": "2018-07-19T16:31:19.401822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive target = 0.251%\n"
     ]
    }
   ],
   "source": [
    "# Inspect data size\n",
    "nclick_total =len(df)\n",
    "percentage_pos = (df['is_attributed'].sum()) / nclick_total * 100\n",
    "print('Percentage of positive target = {:.3f}%'.format(percentage_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[CAUTION] Class imbalance**<br>\n",
    "Given that only __<span class=\"mark\">~0.25%</span>__ of the records has positive target values (`df['is_attributed'] == 1`), we have **an extreme case of class imbalance** at hand.\n",
    "\n",
    "### 2.2 Convert datetime variable to usable form\n",
    "Among the datetime fields such as month, day, and hour-of-the-day, we only keep hour-of-day and name it as `click_hour` for subsequent processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.593134Z",
     "start_time": "2018-07-19T16:31:19.436196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract hour of the day\n",
    "df['click_hour'] = df['click_time'].dt.hour\n",
    "\n",
    "# Drop raw `click_time`\n",
    "df.drop(columns=['click_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.628133Z",
     "start_time": "2018-07-19T16:31:19.594928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>click_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86946</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119349</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73516</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel  is_attributed  click_hour\n",
       "0   86946    3       1  19      379              0          23\n",
       "1  119349    3       1  17      379              0          23\n",
       "2   73516   18       1  22      107              0           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train-test split, and set aside testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.762961Z",
     "start_time": "2018-07-19T16:31:19.629996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (pos%): 0.24939621084641736\n",
      "Testing data (pos%): 0.25346486104501076\n"
     ]
    }
   ],
   "source": [
    "# Split the original dataframe into in-sample training and testing sets\n",
    "# Because stratified sampling is the default option of sklearn, it is not\n",
    "# explicitly set\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Double check class ratios after train-test split\n",
    "print(\n",
    "    'Training data (pos%):',\n",
    "    100 * df_train['is_attributed'].sum() / len(df_train)\n",
    ")\n",
    "print(\n",
    "    'Testing data (pos%):',\n",
    "    100 * df_test['is_attributed'].sum() / len(df_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Inspect variable distributions of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:19.842733Z",
     "start_time": "2018-07-19T16:31:19.765492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>click_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_unique</th>\n",
       "      <td>71528.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_unique (%)</th>\n",
       "      <td>11.052548</td>\n",
       "      <td>0.040793</td>\n",
       "      <td>0.052228</td>\n",
       "      <td>0.028123</td>\n",
       "      <td>0.025959</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.003708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ip         app      device          os     channel  \\\n",
       "n_unique      71528.000000  264.000000  338.000000  182.000000  168.000000   \n",
       "n_unique (%)     11.052548    0.040793    0.052228    0.028123    0.025959   \n",
       "\n",
       "              is_attributed  click_hour  \n",
       "n_unique           2.000000   24.000000  \n",
       "n_unique (%)       0.000309    0.003708  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the amount of unique values\n",
    "df_counts = pd.DataFrame()\n",
    "df_counts['n_unique'] = df_train.nunique()\n",
    "df_counts['n_unique (%)'] = 100 * df_counts['n_unique'] / len(df_train)\n",
    "df_counts.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TAKE AWAY]**<br>\n",
    "* Without exception, the total number of unique values for each of these variables is markedly smaller than the total number of clicks. This indicates that many-to-one mapping is typical between clicks and attributes such as `ip`, `app`, and `device`. This is reasonable given that a single user can generate multiple clicks.\n",
    "* The categorical features at hand are of very high cardinality. Feature engineering is going to be critical in preparing the data for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Apply target-guided encoding to categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:20.942101Z",
     "start_time": "2018-07-19T16:31:19.844907Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_list = [x for x in df_train.columns if x != 'is_attributed']\n",
    "\n",
    "df_train, df_test = preprocessing.df_label2num_encoding(\n",
    "    df_train, df_test, cols=feature_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Check dataframes after encoding\n",
    "\n",
    "Note that mapping used for encoding is generated with training data and then propagated to testing data. \n",
    "Because there are non-overlap variables between training and testing data, and encoded testing data are going to have missing values. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:21.143577Z",
     "start_time": "2018-07-19T16:31:20.944133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>risk_ip</th>\n",
       "      <th>count_ip</th>\n",
       "      <th>risk_app</th>\n",
       "      <th>count_app</th>\n",
       "      <th>risk_device</th>\n",
       "      <th>count_device</th>\n",
       "      <th>risk_os</th>\n",
       "      <th>count_os</th>\n",
       "      <th>risk_channel</th>\n",
       "      <th>count_channel</th>\n",
       "      <th>risk_click_hour</th>\n",
       "      <th>count_click_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nan_train(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nan_test(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.364989</td>\n",
       "      <td>3.364989</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              is_attributed   risk_ip  count_ip  risk_app  count_app  \\\n",
       "nan_train(%)            0.0  0.000000  0.000000  0.000000   0.000000   \n",
       "nan_test(%)             0.0  3.364989  3.364989  0.006129   0.006129   \n",
       "\n",
       "              risk_device  count_device   risk_os  count_os  risk_channel  \\\n",
       "nan_train(%)     0.000000      0.000000  0.000000  0.000000      0.000000   \n",
       "nan_test(%)      0.029565      0.029565  0.004327  0.004327      0.000361   \n",
       "\n",
       "              count_channel  risk_click_hour  count_click_hour  \n",
       "nan_train(%)       0.000000              0.0               0.0  \n",
       "nan_test(%)        0.000361              0.0               0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check presence of missing value after encoding\n",
    "df_nulls = pd.DataFrame()\n",
    "df_nulls['nan_train(%)'] = 100 * (df_train.isnull().sum() / len(df_train))\n",
    "df_nulls['nan_test(%)'] = 100 * (df_test.isnull().sum() / len(df_test))\n",
    "df_nulls.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Machine learning\n",
    "### 3.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:31:21.224956Z",
     "start_time": "2018-07-19T16:31:21.145381Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing.df_to_Xy(df_train)\n",
    "X_test, y_test = preprocessing.df_to_Xy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:37:46.223453Z",
     "start_time": "2018-07-19T16:37:46.191654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647163, 12) (277356, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:56:30.772102Z",
     "start_time": "2018-07-19T16:56:07.511Z"
    }
   },
   "outputs": [],
   "source": [
    "import modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.005205Z",
     "start_time": "2018-07-19T16:31:21.306166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of hyperparameter space: n_hyperparams = 15\n",
      "Hyperparameter search with RandomizedSearchCV\n",
      "assess runtime = 58.67 s\n",
      "0.9960267077341903 0.0003884161257774438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgc = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "param_grid = {\n",
    "    'estimator__penalty': ['l1', 'l2'],\n",
    "    'estimator__C': np.logspace(-5, 5, 11),\n",
    "    'estimator__fit_intercept': [True, False]\n",
    "}\n",
    "model = modeling.Classifier()\n",
    "auc_mean, auc_std = model.assess(lgc, X_train, y_train, param_grid)\n",
    "print(auc_mean, auc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:37:46.190094Z",
     "start_time": "2018-07-19T16:36:53.202608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of hyperparameter space: n_hyperparams = 15\n",
      "Hyperparameter search with RandomizedSearchCV\n",
      "0.8779020639105864\n"
     ]
    }
   ],
   "source": [
    "model = modeling.Classifier()\n",
    "model.fit(lgc, X_train, y_train, param_grid)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "score_test = roc_auc_score(y_test, y_pred)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T17:02:49.024987Z",
     "start_time": "2018-07-19T16:56:33.242064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of hyperparameter space: n_hyperparams = 8\n",
      "Hyperparameter search with RandomizedSearchCV\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   51.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   51.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   58.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   30.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   49.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assess runtime = 375.75 s\n",
      "0.9965586796635021 0.0023162721250465064\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "gbm = xgb.XGBRegressor(n_jobs=-1)\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': np.arange(10, 100, 20),\n",
    "    'estimator__max_depth': np.arange(2, 5)\n",
    "}\n",
    "\n",
    "model = modeling.Classifier()\n",
    "auc_mean, auc_std = model.assess(gbm, X_train, y_train, param_grid)\n",
    "print(auc_mean, auc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T17:14:45.989518Z",
     "start_time": "2018-07-19T17:09:33.158871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of hyperparameter space: n_hyperparams = 8\n",
      "Hyperparameter search with RandomizedSearchCV\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit runtime = 312.50 s\n",
      "0.6916062343253389\n"
     ]
    }
   ],
   "source": [
    "model = modeling.Classifier()\n",
    "model.fit(gbm, X_train, y_train, param_grid)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "score_test = roc_auc_score(y_test, y_pred)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.297106Z",
     "start_time": "2018-07-19T16:31:16.589Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "model_id = 'random_forest'\n",
    "\n",
    "# Modeling\n",
    "forest = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': np.arange(10, 100, 10),\n",
    "    'estimator__max_depth': range(1, 4),\n",
    "    'estimator__min_samples_leaf': np.arange(1, 10)\n",
    "}\n",
    "model = modeling.Classifier()\n",
    "t_start = time.time()\n",
    "auc_mean, auc_std = model.assess(forest, X_train, y_train, param_grid)\n",
    "t_elapsed = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.298675Z",
     "start_time": "2018-07-19T16:31:16.591Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_mean, auc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.299740Z",
     "start_time": "2018-07-19T16:31:16.593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep score\n",
    "df_score_eval[model_id] = (auc_mean, auc_std, t_elapsed)\n",
    "df_score_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.301182Z",
     "start_time": "2018-07-19T16:31:16.594Z"
    }
   },
   "outputs": [],
   "source": [
    "index = np.argsort(model.feature_importances_).astype(int)[::-1]\n",
    "print(index)\n",
    "features = np.array([x for x in df_train.columns if x != 'is_attributed'])\n",
    "features[index]\n",
    "model.feature_importances_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.302326Z",
     "start_time": "2018-07-19T16:31:16.596Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight.compute_class_weight(\n",
    "    'balanced', np.unique(y_train), y_train\n",
    ")\n",
    "print(np.unique(y_train))\n",
    "\n",
    "200.48420074 / 0.5012501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.303451Z",
     "start_time": "2018-07-19T16:31:16.598Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [x for x in df_train.columns if x != 'is_attributed']\n",
    "[print(i, x) for i, x in enumerate(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.304862Z",
     "start_time": "2018-07-19T16:31:16.600Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "param = {'max_depth':2, 'num_trees':100, 'objective':'binary', 'is_unbalanced': True}\n",
    "\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "print(y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T16:32:20.306554Z",
     "start_time": "2018-07-19T16:31:16.602Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(\n",
    "    class_weight='balanced', n_estimators=40, max_depth=3,\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLNDcapstone_pipeline.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
